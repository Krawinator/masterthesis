{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb3b79a4",
   "metadata": {},
   "source": [
    "GrundsÃ¤tzlich: \n",
    "    12009: Wirkleistung\n",
    "    12008: Blindleistung\n",
    "\n",
    "eiot IDs:\n",
    "UW Bollingstedt SÃ¼d Feld E42: \n",
    "    SHNG_E:DSO:SHN:ST:1000364072:SA:110:SF:E42:MSZ::MW:12008    c076ad04-1a18-434d-8e86-34e081b0e4f6\n",
    "    SHNG_E:DSO:SHN:ST:1000364072:SA:110:SF:E42:MSZ::MW:12009    102fa684-58ca-451d-a0ae-6341accc6a36\n",
    "\n",
    "\n",
    "\n",
    "UW Tarp Feld E01:\n",
    "Blindleistung ist nicht gegeben (warum auch immer)\n",
    "    SHNG_E:DSO:SHN:ST:STUW45121:SA:110:SF:E01:MSZ::MW:P     03636523-35f2-428f-86e8-c260fafbe330\n",
    "    SHNG_E:DSO:SHN:ST:STUW45121:SA:110:SF:E01:MSZ::MW:IS    a8b25505-1352-47a1-9798-4c0641cf3302\n",
    "    SHNG_E:DSO:SHN:ST:STUW45121:SA:110:SF:E01:MSZ::MW:U     600fd8d0-e572-4aff-a2ac-7f2b02c18066\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "UW Schuby West Feld E24\n",
    "    SHNG_E:DSO:SHN:ST:STUW47570:SA:110:SF:E24:MSZ::MW:12008\n",
    "    SHNG_E:DSO:SHN:ST:STUW47570:SA:110:SF:E24:MSZ::MW:12009\n",
    "\n",
    "\n",
    "UW JÃ¼bek Ost Feld E01:\n",
    "    Kann ignoriert werden, da es sich hier um einen Erder handelt..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7407cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# definition of paths:\n",
    "# Achte auf die Windows Falle; also einlesen der Pfade mit r\"...\"\n",
    "UW_Boll_P = r\"Daten\\CSV_Raw\\UW Bollingstedt E42 P und Q\\SHNG_E_DSO_SHN_ST_1000364072_SA_110_SF_E42_MSZ__MW_12008_20251001.csv\"\n",
    "UW_Boll_Q = r\"Daten\\CSV_Raw\\UW Bollingstedt E42 P und Q\\SHNG_E_DSO_SHN_ST_1000364072_SA_110_SF_E42_MSZ__MW_12009_20251001.csv\"\n",
    "\n",
    "UW_Tarp_IS = r\"Daten\\CSV_Raw\\UW Tarp E01 P IS und U\\SHNG_E_DSO_SHN_ST_STUW45121_SA_110_SF_E01_MSZ__MW_IS_20251001.csv\"\n",
    "UW_Tarp_U  = r\"Daten\\CSV_Raw\\UW Tarp E01 P IS und U\\SHNG_E_DSO_SHN_ST_STUW45121_SA_110_SF_E01_MSZ__MW_U_20251001.csv\"\n",
    "\n",
    "UW_Schuby_P = r\"Daten\\CSV_Raw\\UW Schuby West\\SHNG_E_DSO_SHN_ST_STUW47570_SA_110_SF_E24_MSZ__MW_12008_20251001.csv\"\n",
    "UW_Schuby_Q = r\"Daten\\CSV_Raw\\UW Schuby West\\SHNG_E_DSO_SHN_ST_STUW47570_SA_110_SF_E24_MSZ__MW_12009_20251001.csv\"\n",
    "# =========================\n",
    "\n",
    "\n",
    "SQRT3 = np.sqrt(3.0)\n",
    "\n",
    "def S_from_P_Q(P_MW, Q_MVAr, signed=True):\n",
    "    \"\"\"\n",
    "    Berechnet S aus P und Q.\n",
    "    Wenn signed=True, wird das Vorzeichen von P Ã¼bernommen.\n",
    "    \"\"\"\n",
    "    P = pd.Series(P_MW, dtype=\"float64\")\n",
    "    Q = pd.Series(Q_MVAr, dtype=\"float64\")\n",
    "    S_abs = np.sqrt(P.pow(2) + Q.pow(2))\n",
    "    if signed:\n",
    "        return np.sign(P) * S_abs\n",
    "    else:\n",
    "        return S_abs\n",
    "\n",
    "\n",
    "def S_from_U_IS(U_kV, I_A, signed=True):\n",
    "    \"\"\"\n",
    "    Berechnet S aus U [kV] und I [A] (Dreiphasen).\n",
    "    Ergebnis in MVA.\n",
    "    Wenn signed=True, wird das Vorzeichen von I Ã¼bernommen.\n",
    "    \"\"\"\n",
    "    U = pd.Series(U_kV, dtype=\"float64\")\n",
    "    I = pd.Series(I_A, dtype=\"float64\") / 1000.0  # A â†’ kA\n",
    "    S_abs = SQRT3 * U.abs() * I.abs()\n",
    "    if signed:\n",
    "        return np.sign(I) * S_abs\n",
    "    else:\n",
    "        return S_abs\n",
    "\n",
    "\n",
    "\n",
    "# CSVs einlesen (immer nur 2 Spalten, Timestamp + Wert)\n",
    "df_boll_p = pd.read_csv(UW_Boll_P, sep=\",\", header=0)\n",
    "df_boll_q = pd.read_csv(UW_Boll_Q, sep=\",\", header=0)\n",
    "\n",
    "df_tarp_is = pd.read_csv(UW_Tarp_IS, sep=\",\", header=0)\n",
    "df_tarp_u  = pd.read_csv(UW_Tarp_U,  sep=\",\", header=0)\n",
    "\n",
    "df_schuby_p = pd.read_csv(UW_Schuby_P, sep=\",\", header=0)\n",
    "df_schuby_q = pd.read_csv(UW_Schuby_Q, sep=\",\", header=0)\n",
    "\n",
    "# Scheinleistung berechnen\n",
    "S_boll = S_from_P_Q(df_boll_p.iloc[:,1], df_boll_q.iloc[:,1])\n",
    "S_tarp = S_from_U_IS(df_tarp_u.iloc[:,1], df_tarp_is.iloc[:,1])\n",
    "S_schuby = S_from_P_Q(df_schuby_p.iloc[:,1], df_schuby_q.iloc[:,1])\n",
    "\n",
    "# Ergebnisse in DataFrames mit Zeitstempel zusammenfÃ¼hren\n",
    "df_boll_result = pd.DataFrame({\n",
    "    \"timestamp\": pd.to_datetime(df_boll_p.iloc[:,0]),\n",
    "    \"S_MVA\": S_boll\n",
    "})\n",
    "\n",
    "df_tarp_result = pd.DataFrame({\n",
    "    \"timestamp\": pd.to_datetime(df_tarp_u.iloc[:,0]),\n",
    "    \"S_MVA\": S_tarp\n",
    "})\n",
    "\n",
    "df_schuby_result = pd.DataFrame({\n",
    "    \"timestamp\": pd.to_datetime(df_schuby_p.iloc[:,0]),\n",
    "    \"S_MVA\": S_schuby\n",
    "})\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Merge auf gemeinsame Zeitbasis\n",
    "# -----------------------------\n",
    "df_merge = (\n",
    "    df_boll_result[[\"timestamp\", \"S_MVA\"]]\n",
    "    .merge(df_tarp_result[[\"timestamp\", \"S_MVA\"]], on=\"timestamp\", how=\"inner\", suffixes=(\"_Boll\", \"_Tarp\"))\n",
    "    .merge(df_schuby_result[[\"timestamp\", \"S_MVA\"]], on=\"timestamp\", how=\"inner\")\n",
    "    .rename(columns={\"S_MVA\": \"S_Schuby\"})\n",
    "    .sort_values(\"timestamp\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Wenn du bereits signiertes S in den Einzel-DFs berechnet hast (Spalte 'S_signed'),\n",
    "# kannst du die folgenden optionalen Ersetzungen aktivieren:\n",
    "if \"S_signed\" in df_boll_result.columns:\n",
    "    df_merge[\"S_MVA_Boll\"] = df_boll_result.set_index(\"timestamp\").loc[df_merge[\"timestamp\"], \"S_signed\"].to_numpy()\n",
    "if \"S_signed\" in df_tarp_result.columns:\n",
    "    df_merge[\"S_MVA_Tarp\"] = df_tarp_result.set_index(\"timestamp\").loc[df_merge[\"timestamp\"], \"S_signed\"].to_numpy()\n",
    "if \"S_signed\" in df_schuby_result.columns:\n",
    "    df_merge[\"S_Schuby\"] = df_schuby_result.set_index(\"timestamp\").loc[df_merge[\"timestamp\"], \"S_signed\"].to_numpy()\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Î”S bilden\n",
    "# -----------------------------\n",
    "df_merge[\"dS_Boll\"]   = df_merge[\"S_MVA_Boll\"].diff()\n",
    "df_merge[\"dS_Tarp\"]   = df_merge[\"S_MVA_Tarp\"].diff()\n",
    "df_merge[\"dS_Schuby\"] = df_merge[\"S_Schuby\"].diff()\n",
    "\n",
    "# Erste Zeile fÃ¤llt wegen diff() raus\n",
    "df_merge = df_merge.dropna(subset=[\"dS_Boll\", \"dS_Tarp\", \"dS_Schuby\"]).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Spikes in Boll erkennen\n",
    "#    Variante A: fixer Î”S-Schwellenwert (einfach)\n",
    "# -----------------------------\n",
    "threshold = 30.0  # MVA â€“ an deine Daten anpassen\n",
    "spike_idx = df_merge.index[df_merge[\"dS_Boll\"].abs() > threshold].to_list()\n",
    "\n",
    "\n",
    "print(f\"Anzahl erkannter Spikes in Boll: {len(spike_idx)}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Fenster um Spikes sammeln (um Reaktion in Nachbarn mitzunehmen)\n",
    "# -----------------------------\n",
    "window = 2  # z.B. die 2 Punkte davor und danach mitnehmen\n",
    "use_rows = set()\n",
    "for i in spike_idx:\n",
    "    for j in range(max(0, i - window), min(len(df_merge), i + window + 1)):\n",
    "        use_rows.add(j)\n",
    "use_rows = sorted(use_rows)\n",
    "\n",
    "df_spikes = df_merge.iloc[use_rows].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Korrelation NUR auf Spike-Phasen (Î”S)\n",
    "# -----------------------------\n",
    "corr_matrix = df_spikes[[\"dS_Boll\", \"dS_Tarp\", \"dS_Schuby\"]].corr(method=\"pearson\")\n",
    "print(\"\\nKorrelationsmatrix (nur Spike-Phasen, auf Î”S):\")\n",
    "print(corr_matrix)\n",
    "\n",
    "corr_boll_tarp   = corr_matrix.loc[\"dS_Boll\", \"dS_Tarp\"]\n",
    "corr_boll_schuby = corr_matrix.loc[\"dS_Boll\", \"dS_Schuby\"]\n",
    "\n",
    "print(f\"\\nKorrelation Î”Bollâ€“Î”Tarp (Spikes):   {corr_boll_tarp:.3f}\")\n",
    "print(f\"Korrelation Î”Bollâ€“Î”Schuby (Spikes): {corr_boll_schuby:.3f}\")\n",
    "\n",
    "if abs(corr_boll_tarp) > abs(corr_boll_schuby):\n",
    "    print(\"ðŸ‘‰ Bei Spikes hÃ¤ngt Boll stÃ¤rker mit Tarp zusammen.\")\n",
    "else:\n",
    "    print(\"ðŸ‘‰ Bei Spikes hÃ¤ngt Boll stÃ¤rker mit Schuby zusammen.\")\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# --- Regression Î”Tarp ~ Î”Boll ---\n",
    "X = df_spikes[\"dS_Boll\"]\n",
    "X = sm.add_constant(X)  # Bias/Intercept erlauben\n",
    "y = df_spikes[\"dS_Tarp\"]\n",
    "\n",
    "model_tarp = sm.OLS(y, X).fit()\n",
    "print(\"\\nRegression Î”Tarp ~ Î”Boll\")\n",
    "print(model_tarp.summary())\n",
    "\n",
    "# SensitivitÃ¤tsfaktor (Steigung):\n",
    "a_tarp = model_tarp.params[\"dS_Boll\"]\n",
    "print(f\"SensitivitÃ¤t Tarp: Î”Tarp â‰ˆ {a_tarp:.2f} * Î”Boll\")\n",
    "\n",
    "# --- Regression Î”Schuby ~ Î”Boll ---\n",
    "X = df_spikes[\"dS_Boll\"]\n",
    "X = sm.add_constant(X)\n",
    "y = df_spikes[\"dS_Schuby\"]\n",
    "\n",
    "model_schuby = sm.OLS(y, X).fit()\n",
    "print(\"\\nRegression Î”Schuby ~ Î”Boll\")\n",
    "print(model_schuby.summary())\n",
    "\n",
    "b_schuby = model_schuby.params[\"dS_Boll\"]\n",
    "print(f\"SensitivitÃ¤t Schuby: Î”Schuby â‰ˆ {b_schuby:.2f} * Î”Boll\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
